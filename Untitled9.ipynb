{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled9.ipynb","provenance":[],"authorship_tag":"ABX9TyMW632wPhGYdpeAeIFDIPfD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Z-a92It1LzKp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"74913f31-b8d0-43ef-ded8-690cf5a0bd93","executionInfo":{"status":"ok","timestamp":1590668804873,"user_tz":-330,"elapsed":104067,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iuf94sQiPeQl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9d318413-4d2a-4904-8bab-277f3f383937","executionInfo":{"status":"ok","timestamp":1590668853148,"user_tz":-330,"elapsed":3513,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["\n","from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BsN5p9VVQHGJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"d1a7d3a9-02ee-41af-eb6e-cf22a04e65d3","executionInfo":{"status":"ok","timestamp":1590668953011,"user_tz":-330,"elapsed":13314,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["IMAGE_SIZE = [224, 224]\n","\n","train_path = '/content/drive/My Drive/Colab Notebooks/mask detection/train'\n","valid_path = '/content/drive/My Drive/Colab Notebooks/mask detection/test'\n","\n","# add preprocessing layer to the front of VGG\n","vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n","\n","# don't train existing weights\n","for layer in vgg.layers:\n","  layer.trainable = False\n","  \n","\n","  \n","  # useful for getting number of classes\n","folders = glob('/content/drive/My Drive/Colab Notebooks/mask detection/train/*')\n","  "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d3gKg9qwQdFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":867},"outputId":"4472ba1f-60b8-4fb9-f08d-049684e7e27d","executionInfo":{"status":"ok","timestamp":1590668981849,"user_tz":-330,"elapsed":1404,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["x = Flatten()(vgg.output)\n","# x = Dense(1000, activation='relu')(x)\n","prediction = Dense(len(folders), activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=vgg.input, outputs=prediction)\n","\n","# view the structure of the model\n","model.summary()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 50178     \n","=================================================================\n","Total params: 14,764,866\n","Trainable params: 50,178\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wUOT4mHsQnCI","colab_type":"code","colab":{}},"source":["model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdH2FMifQqra","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qChUYjS7QulX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d11b7321-814e-4893-ca2d-c68fb59cf612","executionInfo":{"status":"ok","timestamp":1590669052812,"user_tz":-330,"elapsed":2622,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/mask detection/train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","\n","test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/mask detection/test',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 1314 images belonging to 2 classes.\n","Found 194 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jw0kz4IDQxdb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"97db5962-317c-4074-ef18-6895faa7eb10","executionInfo":{"status":"ok","timestamp":1590669719709,"user_tz":-330,"elapsed":639899,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["r = model.fit_generator(\n","  training_set,\n","  validation_data=test_set,\n","  epochs=5,\n","  steps_per_epoch=len(training_set),\n","  validation_steps=len(test_set)\n",")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","42/42 [==============================] - 545s 13s/step - loss: 0.3645 - accuracy: 0.8577 - val_loss: 0.0032 - val_accuracy: 0.9742\n","Epoch 2/5\n","42/42 [==============================] - 23s 550ms/step - loss: 0.0360 - accuracy: 0.9939 - val_loss: 0.0608 - val_accuracy: 0.9794\n","Epoch 3/5\n","42/42 [==============================] - 23s 553ms/step - loss: 0.0252 - accuracy: 0.9970 - val_loss: 0.0673 - val_accuracy: 0.9794\n","Epoch 4/5\n","42/42 [==============================] - 23s 548ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 3.5949e-04 - val_accuracy: 0.9794\n","Epoch 5/5\n","42/42 [==============================] - 23s 553ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 3.8861e-05 - val_accuracy: 0.9794\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X4D22PSVQ_Sv","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","\n","model.save('mask.h5')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZBiPAHDTgyB","colab_type":"code","colab":{}},"source":["\n","accuracy = r.history['accuracy']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufQBbnnqUPRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1c599788-1c76-4877-8fb9-8d128e04c271","executionInfo":{"status":"ok","timestamp":1590669968611,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Naveen Sharma","photoUrl":"","userId":"01512903222798654080"}}},"source":["accuracy"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.85768646, 0.99391174, 0.9969559, 0.9969559, 0.9977169]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"GzSUNOBgUX_r","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}